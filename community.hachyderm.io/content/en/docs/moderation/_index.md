---
title: "Moderation Guiding Principles"
linkTitle: "Moderation Guiding Principles"
weight: 4
description: >
  Hachyderm Moderation: Process and Responsibilities
---

This page includes:

* Information about how we moderate Hachyderm.
* The responsibilities of members (Hachydermians) and moderators
(the "we/us" of this document).
* Other supporting context relevant to the moderation process.

We appreciate that this is probably not the page that you are
coming to for light reading. Most likely you are here because you
have been moderated and are trying to figure out what to do
or you are a prospective user and you are trying to figure out if
this instance is a safe home for you. We are here for you and have
tried to build as comprehensive and clear a document as possible.

For full transparency: we are currently designing our
documentation architecture, so it is likely
that this singular document will be split onto different pages for
clarity. Please keep this in mind if you are bookmarking this
page.

(Skip to the [Help, I was moderated!](#help-i-was-moderated)
section.)

# Responsibilities 

## Hachydermians

**Hachydermians are responsible for their own actions.** This means:

1. Each Hachydermian is responsible for following server rules
(and relevant laws).
1. Each Hachydermian is responsible for ensuring that their
participation in the fediverse is collaboratively aligned.
1. Each Hachydermian acknowledges that it is our collective
responsibility to create and steward the interactions we want to
see.
1. Each Hachydermian is responsible for their own learning and growth.

## Moderators (of Hachyderm)

**Moderators are responsible for stewarding safe spaces by
enforcing good conduct.** This means:

1. "Good conduct" here means "following server rules and local
laws."
1. Moderators acknowledge that it is to the benefit of all to
optimize on maximizing each user's ability to interact with as
much of the fediverse as possible.
1. Moderators acknowledge that some users are more vulnerable than
other users. Who is most vulnerable will be situationally
dependent based on the intersectionality at play.
1. Moderators acknowledge that while intent matters, we can only
act based on the impact of a user's actions.
1. Moderators take ownership of balancing open federation with
protecting the most vulnerable for all situations that fall under
our scope.
1. Moderators take ownership of protecting Hachyderm as the scope
of moderation, which means using the tools and resources we have
available for Hachydermians interacting in the fediverse and the
fediverse interacting with Hachydermians.

Note that moderators, in this case, are viewing all users in an
interaction and not only the Hachydermians involved. The
implications of this will be covered in the rest of this document.

# Moderation of Hachyderm

Moderation action is required when a user's actions puts that
user's ability to openly federate in conflict with the moderators'
responsibility to protect the most vulnerable. What this means in
practice will depend on many factors. The questions the moderators
will need to answer in each scenario are:

- Is this a first incident or a repeated incident?
- What is the impact of this incident?
  - What is the impact of repeated incidents?
- Who is (or are) the most vulnerable in this situation?
- What are the limits of our ability to moderate this situation?

To elaborate, depending on whether an incident is a user's first
incident and the severity of the incident itself will determine
the course and reversibility of moderator action. We also consider
that the potential for learning and growth are happening at the
expense of one more people, including but not limited to other
user(s) that the reported user is interacting with, the reported
user themself, or both. The types of actions that
moderators can take are based on the tools provided by Mastodon.
These are covered in [our Reporting
document](../reporting) as well as [Mastodon's
moderation actions documentation](https://docs.joinmastodon.org/admin/moderation/),
but to summarize:

1. For Hachydermians, i.e. those with accounts on our server:
   - Warn, Freeze, Force-Sensitive, Limit, Suspend
1. For individual non-Hachydermians, i.e. users with accounts not
based on Hachyderm:
   - Force-Sensitive, Limit, Suspend
1. For servers on the fediverse:
   - Reject Media, Limit (Silence), Suspend

We have more detail on what moderators see when we receive reports
in our [Reporting document](../reporting), but essentially what
moderation actions can and should be taken depends on the source
that is being reported.

It is also important to understand that users _not_ based on
Hachyderm are not bound by the Hachyderm server rules. What this
means is that moderators will only take action on off-server
interactions that 1 ) are reported and 2 ) compromise safe space. To put it another way,
although Hachyderm has a rule limiting the number of corporate
accounts, we do not prevent Hachydermians from engaging with
corporate accounts on other servers. The same holds true for bots
and other account types that have different rules here.
Hachydermians participating with other individuals on the
fediverse, or with the accounts of entities and bots, is all fine. We would only take
action when those engagements infringe on safe spaces, e.g. if the
other user or entity is engaging in transphobic or anti-Black
actions, violating laws, or risking / at risk of compromising the
integrity of the Hachyderm infrastructure (accounts or servers as
attack vectors).

Moderators see all reports filed by Hachydermians to other servers
as well as receive all reports filed against
Hachydermians. This is covered in more detail in the
[Reporting document](../reporting). What this does is allow us to
limit or prevent federating with either individual accounts or
domains of services that are infringing either on Hachyderm as a
safe space or Hachyderm's infrastructure. As you can see from the
short list above, moderators _cannot_ send warnings to users of
other instances: they are not bound by our rules. If we see a
report for a user that is not in violation of Hachyderm as a safe
space, does not violate any laws, and does not infringe on Hachyderm's
ability to operate, we leave the moderation action to the reported user's
home instance and do not take additional moderator action.

# A Couple Quick Clarifiers

There are a couple common questions / concerns that come up in
moderation that we wanted to handle here openly and directly.

## Open federation

The "Paradox of Tolerance", or what could be referred to as the "Openness
Paradox" (as a reference to open federation), can be summarized
as: tolerance without limit necessarily includes tolerance of intolerance.
Discussion of this usually goes a bit further to cover the
consequences, historical and modern, of tolerating intolerance.
(Full discussion of this exceeds the scope of this article, but for additional
reading start with [The Paradox of
Tolerance](https://en.wikipedia.org/wiki/Paradox_of_tolerance)
Wikipedia page.)

Succinctly: Hachyderm is not open for openness' sake and is not
unlimitedly so. Moderators take ownership to keep Hachyderm **_as open as possible_**;
however, we will put limits on openness to protect Hachydermians,
full stop.

## Over- vs Under- representation

Why this section is included will become appearant, please read
the scenario and clarifier that ties it all in.

---

This section will start with a familiar scenario: the senior
engineer at a tech company. To keep the scenario simple, we'll say
"small company". Certain duties fall to the most senior
engineer(s), many of which can be categorized as communication and/or
education. They may onboard new engineers that are either less
experienced than they are or who are their peers ("new" to company,
not "new" to industry). They make and communicate decisions to
their peers, subordinates, and management layers.

The number of engineers functioning at this level is usually
limited. It takes time and study to grow in a field of expertise
and engineering is no different. That means in general there are
"more" level I engineers than level II, "more" level II than level
III, and so forth. ("More" being flexible in exact value.) What
_can_, and frequently _does_, happen is when there's not a good
headcount ratio is that the more senior engineers get burned out
by the demands on their time.

### What does this have to do with over- / under- representation?

One of the most significant factors for the burnout was called out
directly: headcount. That is to say, "too many of them and not
enough of me".

We all learn from each other. Each Hachydermian, moderator,
maintainer, and user, acknowledges that for any given
demographic there is going to be the "too many of you and too few
of me" problem. Specifically: historically underrepresented groups
quite directly suffer from the "too many of them, too few of me"
problem when interacting with historically overrepresented groups.
That means by default those who are underrepresented have already
learned to interact with those who are overrepresented, but those
who are overrepresented have not necessarily learned how to
interact with those who are underrepresented.

In order to equitably share the burden of shared learning and
growth, each Hachydermian acknowledges that some
intersectionalities will spend a _lot_ of energy educating those
outside their own demographic(s). This includes but is not limited
to: what is it like to be Black? What is it like to be chronically
ill? What is it like to be ....?

Part of being a Hachydermian is that we make a promise to do our
best by each other and that we will do our due dilligence to learn
and grow by pursuing our own research and not disproportionately
place the burden of education on others. Succintly: we will
"google" both to develop a broader awareness of our world as well
as "what the _heck_ is this Java Exception???" **We
will also always show appreciation for, but not expectation of, the time that those who
choose to educate give as education is a gift and time is a
gift.** (Especially since, relevantly, it is likely that person's 50th time
having that conversation even if it is your first.)

### What does this have to do with moderation?

This most frequently comes up in a moderation context when one
user felt either entitled to another user's time and/or space,
which would fall under our "Don't Be A Dick" policy. For the
reasons explained above, historically underrepresented groups are
most impacted.

# Help, I was moderated!

Logistical constraint that all users need to keep in mind:

- Due to limitations in the moderation interface, we cannot go
  back-and-forth with you via the admin UI.
  - We actually have an issue open about this on [Mastodon's issue tracker](https://github.com/mastodon/mastodon/issues/21531).
- This means in order to discuss your Appeal further, we will need
  you to email [admin@hachyderm.io](mailto:admin@hachyderm.io)
  _and_ indicate you have done so in the text of your Appeal
  message.
- In the event that you didn't email the Admin email (happens
  often), we willy likely replicate the last moderation action
  (typically warn, freeze, suspend) to get the admin interface to
  re-trigger our ability to send you a message. We appreciate that
  the "undo" / "redo" impact of this action is frustrating, but it
  is the only course available to us at this time.

## Expectations of the moderation process

Moderators will always treat moderated users with respect. We will
do our best, where appropriate, to communicate the what and why of
your moderation. We will not typically link the individual threads
or posts that were included in the report. This is because, as
moderators, we have a duty to the community overall. This means
that we also have a responsibility to ensure that:

- We do not cause a repeat of the behavior that caused a report to
  be filed in the first place.
- We do not create a situation wher other users in the thread /
  interaction, and/or the user who reported the situation, are
  open to later harassment. This includes from other users or from
  the same / reported user using alternate accounts.

In situations where we _do_ provide this information, we are doing
it for your benefit so you can learn and grow. What we expect in that
situation is that you do not use the information to cause further
harm, intentional or unintentional. For the latter, if you are
unsure how to avoid continuing to cause harm, remember that you
can always recuse yourself from an interaction and you do not
necessarily even need to call out that you are doing so.

If you _do_ use that information to cause additional harm, we will
intervene in a way that 1 ) prioritizes the safety of the
impacted, 2 ) takes responsibility for how we caused that
situation to continue, even if it was unintentional, and 3 )
prevents the situation from continuing to recur.

## The goals of moderation

The main goal of moderation is to stop harmful activity in
progress and prevent it from continuing or recurring. We, as moderators,
promise to take actions that protect the community while
also being responsive to those who would like to rectify their
situations. This can mean either as a Hachydermian federating with
the fediverse or, in the case of external users / servers,
federating with Hachyderm.

If you have been moderated, the most common pattern you will see
is that we will ask you to remedy the situation in some way. If,
for example, you posted something that was reported we will likely
ask you to remove it rather than us removing it. This is because
Hachydermians are ultimately responsible for their own
actions. So **_if something happened that created a need for
moderator involvement, then something needs to happen to remove
that involvement._** We will do our best to ensure that our requests
are time bounded. For example, instead of "please delete this post" you will
likely receive "please delete this post within two days". The goal of
this is to find balance between giving you a reasonable time to
respond, expectation of closure, and reduce moderator burden
(checking indefinitely).

## Moderators are human and the appeals process

We as moderators do our best to take actions that suit the
situation and prevent further harm and communicate what we can.
That said, we are all human which means we can make mistakes. In
the event that you received moderation action that was either
unclear or that you believe did not apply to your actions /
situation, please communicate that to us! It is not our goal to
create frustration and friction. In these situations we ask that
you communicate with us what we would need to know to reverse /
change the decision, such as supplying addtional context, or ask
for the clarifiations you need around what happened and what can
be done to move forward. As a reminder, since we cannot go
back-and-forth in the admin UI, you should include this
information **_both_** in your appeal **_and_** let us know you are emailing us at
[admin@hachyderm.io](mailto:admin@hachyderm.io). This is so we can
keep track of the parent appeal in the UI but also know there is
additional information in our inbox that needs to be responded to.

## FAQ

1. I was moderated, but I'm not sure where to go from here?</br>
Please appeal **_and_** email us at
[admin@hachyderm.io](mailto:admin@hachyderm.io) so we can continue
the conversation with you.
1. Why was I [insert moderation action] if you wanted me to
[perform user action]?<br />
As moderators, we have a duty to the community to try to halt a
situation in progress. If we have reason to believe that a
situation will continue / escalate, we will (likely) moderate with freeze /
suspend, even if what we end up asking of you is to agree to
delete posts in a certain timeframe and/or stop engaging. To
repeat, this is so we can stop whatever is in progress while we
wait on the reported user.
1. Why was I [moderation action] for something that happened
[timeframe]?<br />
As moderators, we need to use our best judgement to determine if a
situation is still ongoing or not due to the highly async nature
of social media. A "day old" thread in social media terms _may_
still be active, and so on.
1. Why can't I know more information about what was included in
the report?<br />
We do our best to balance transparency with the need to moderate a
situation involving (usually) multiple people that we (also
usually) don't know. So realistically when we're making our best
judgements about if a situation will continue to escalate and what
needs to happen to prevent that, we are doing so from a blank
slate. Since we do not know the individuals involved, we use what we know of people in general.
e.g. "Would someone try to 'follow up' with other users based on
this information?" "Would someone know that even if they didn't
mean it to be a problem or cause upset, that someone would likely
be very distressed to file a moderation report only to have the
reported user follow up, no matter the intent or tone?"
